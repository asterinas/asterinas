name: "Benchmark x86-64  "
on:
  # In case of manual trigger, use workflow_dispatch
  workflow_dispatch:
  schedule:
    # Schedule to run on every day at 20:00 UTC (04:00 Beijing Time)
    - cron: '0 20 * * *'

jobs:
  Benchmarks:
    runs-on: self-hosted
    strategy:
      matrix:
        benchmarks: 
          - sysbench/cpu_lat
          - sysbench/thread_lat
          # Memory-related benchmarks
          - lmbench/mem_read_bw
          - lmbench/mem_write_bw
          - lmbench/mem_copy_bw
          - lmbench/mem_pagefault_lat
          - lmbench/mem_mmap_bw
          - lmbench/mem_mmap_lat
          # Process-related benchmarks
          - lmbench/process_getppid_lat
          - lmbench/process_ctx_lat
          - lmbench/process_fork_lat
          - lmbench/process_exec_lat
          - lmbench/process_shell_lat
          # Signal-related benchmarks
          - lmbench/signal_catch_lat
          - lmbench/signal_install_lat
          - lmbench/signal_prot_lat
          # IPC-related benchmarks
          - lmbench/pipe_lat
          - lmbench/pipe_bw
          - lmbench/fifo_lat
          - lmbench/semaphore_lat
          - lmbench/unix_lat
          - lmbench/unix_bw
          - lmbench/unix_connect_lat
          # Syscall-related benchmarks
          - lmbench/vfs_fstat_lat
          - lmbench/vfs_open_lat
          - lmbench/vfs_stat_lat
          - lmbench/vfs_write_lat
          - lmbench/vfs_read_lat
          - lmbench/vfs_select_lat
          - lmbench/vfs_fcntl_lat
          - lmbench/vfs_read_pagecache_bw
          # File-related benchmarks
          - lmbench/ramfs_create_delete_files_0k_ops
          - lmbench/ramfs_create_delete_files_10k_ops
          - lmbench/ramfs_copy_files_bw
          - lmbench/ext2_create_delete_files_0k_ops
          - lmbench/ext2_create_delete_files_10k_ops
          - lmbench/ext2_copy_files_bw
          - fio/ext2_seq_write_bw
          - fio/ext2_seq_read_bw
          - fio/ext2_seq_write_bw_no_iommu
          - fio/ext2_seq_read_bw_no_iommu
          # Loopback-related network benchmarks
          - lmbench/tcp_loopback_bw_128
          - lmbench/tcp_loopback_bw_4k
          - lmbench/tcp_loopback_bw_64k
          - lmbench/tcp_loopback_lat
          - lmbench/tcp_loopback_connect_lat
          - lmbench/tcp_loopback_select_lat
          - lmbench/tcp_loopback_http_bw
          - lmbench/udp_loopback_lat
          # VirtIO-net-related network benchmarks
          - lmbench/tcp_virtio_bw_128
          - lmbench/tcp_virtio_bw_64k
          - lmbench/tcp_virtio_connect_lat
          - lmbench/tcp_virtio_lat
          - lmbench/udp_virtio_lat 
          - iperf3/tcp_virtio_bw
          # Scheduler-related benchmarks
          - hackbench/group8_smp1
          # FIXME: hackbench panics on multi-core settings now.
          # - hackbench/group8_smp8
          # - hackbench/group8_smp16
          - schbench/smp1
          - schbench/smp8
          # Nginx benchmarks
          - nginx/http_req10k_conc1_bw
          - nginx/http_req10k_conc20_bw
          - nginx/http_file4KB_bw
          - nginx/http_file8KB_bw
          - nginx/http_file16KB_bw
          - nginx/http_file32KB_bw
          - nginx/http_file64KB_bw
          # Redis benchmarks
          - redis/ping_inline_100k_conc20_rps
          - redis/ping_mbulk_100k_conc20_rps
          - redis/get_100k_conc20_rps
          - redis/set_100k_conc20_rps
          # SQLite benchmarks
          - sqlite/ext2_benchmarks
          - sqlite/ramfs_benchmarks
          # Memcached benchmarks
          - memcached/t8_conc32_window10k
          - memcached/t8_conc32_window20k
          - memcached/t16_conc64_window10k
      fail-fast: false
      # FIXME: Remove the following line after fixing the parallel execution of network benchmarks.
      max-parallel: 1
    timeout-minutes: 60
    container: 
      image: asterinas/asterinas:0.14.1-20250326
      options: --device=/dev/kvm --privileged

    steps:
      - uses: actions/checkout@v4
      - name: Set up the environment
        run: |
          chmod +x test/benchmark/bench_linux_and_aster.sh
          # Set up git due to the network issue on the self-hosted runner
          git config --global --add safe.directory /__w/asterinas/asterinas
          git config --global http.sslVerify false
          git config --global http.version HTTP/1.1

      - name: Run benchmarks
        run: |
          make install_osdk
          bash test/benchmark/bench_linux_and_aster.sh "${{ matrix.benchmarks }}"
          BENCHMARK_ARTIFACT=results_$(echo "${{ matrix.benchmarks }}" | tr '/' '-')
          echo "BENCHMARK_ARTIFACT=$BENCHMARK_ARTIFACT" >> $GITHUB_ENV

      - name: Store benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.BENCHMARK_ARTIFACT }}
          if-no-files-found: error # Fail the benchmark job if no file is found.
          path: |
            result_*.json

  Results:
    runs-on: ubuntu-latest
    needs: Benchmarks
    if: always()

    steps:
      - uses: actions/checkout@v4
      - name: Download Benchmark Results
        uses: actions/download-artifact@v4
        with:
          pattern: results_*
          path: ./results
          merge-multiple: true

      - name: Set up the environment
        run: |
          sudo apt-get update && sudo apt-get install -y yq jq

      - name: Generate all benchmark config files
        run: |
          mkdir -p configs
          BENCHMARK_LIST=$(ls results/result_*.json | sed 's/.*result_//' | sed 's/\.json//' | jq -R -s -c 'split("\n")[:-1]')
          echo "Processing benchmarks: $BENCHMARK_LIST"

          # Loop through the benchmark identifiers provided by the Matrix job
          for benchmark_id in $(echo "$BENCHMARK_LIST" | jq -r '.[]'); do
            echo "--- Processing $benchmark_id ---"
            BENCHMARK_DIR=$(echo "$benchmark_id" | sed 's/-/\//g')
            BENCHMARK_SUITE=$(echo "$BENCHMARK_DIR" | awk -F'/' '{print $1}')
            BENCHMARK_NAME=$(echo "$BENCHMARK_DIR" | sed -E 's|^[^/]+/||; s|/bench_results||g; s|/|_|g')
            BENCH_RESULT_YAML="test/benchmark/${BENCHMARK_DIR}/bench_result.yaml"
            [ -f "$BENCH_RESULT_YAML" ] || BENCH_RESULT_YAML="test/benchmark/${BENCHMARK_DIR}.yaml"

            if [ ! -f "$BENCH_RESULT_YAML" ]; then
              echo "Warning: YAML file not found for $benchmark_id at $BENCH_RESULT_YAML. Skipping config generation."
              continue
            fi

            # Extract data using yq
            ALERT_THRESHOLD=$(yq -r '.alert.threshold // "130%"' "$BENCH_RESULT_YAML")
            ALERT_TOOL=$(yq -r 'if (.alert.bigger_is_better == true) then "customBiggerIsBetter" else "customSmallerIsBetter" end' "$BENCH_RESULT_YAML")
            TITLE=$(yq -r '.chart.title // "Undefined"' "$BENCH_RESULT_YAML")
            DESCRIPTION=$(yq -r '.chart.description // "No description provided"' "$BENCH_RESULT_YAML")

            # Generate summary JSON if needed (only once per suite)
            SUMMARY_JSON="test/benchmark/$BENCHMARK_SUITE/summary.json"
            if [ ! -f "$SUMMARY_JSON" ]; then
               SUMMARY_YAML="test/benchmark/$BENCHMARK_SUITE/summary.yaml"
               if [ -f "$SUMMARY_YAML" ]; then
                 yq . "$SUMMARY_YAML" > "$SUMMARY_JSON"
                 echo "Generated $SUMMARY_JSON"
               else
                 echo "Warning: summary.yaml not found for suite $BENCHMARK_SUITE"
               fi
            fi

            # Define file paths
            CONFIG_FILE="configs/config_${benchmark_id}.json"
            RESULT_FILE="results/result_${benchmark_id}.json"
          
            # Create JSON structure using jq
            jq -n \
              --arg title "$TITLE" \
              --arg description "$DESCRIPTION" \
              --arg suite "$BENCHMARK_SUITE" \
              --arg name "$BENCHMARK_NAME" \
              --arg threshold "$ALERT_THRESHOLD" \
              --arg tool "$ALERT_TOOL" \
              --arg result_path "$RESULT_FILE" \
              --arg summary_path "$SUMMARY_JSON" \
              '{
                metadata: {
                  title: $title,
                  description: $description,
                  suite: $suite,
                  name: $name,
                  threshold: $threshold,
                  tool: $tool,
                  summary: $summary_path
                },
                result: $result_path
              }' > "$CONFIG_FILE"

            echo "Generated config file $CONFIG_FILE"
          done

      - name: Store benchmark results
        uses: asterinas/github-action-benchmark@v5
        with:
          # Use glob pattern to find all generated config files
          output-file-path: "configs/config_*.json"
          github-token: ${{ secrets.BENCHMARK_SECRET }}
          gh-repository: 'github.com/asterinas/benchmark'
          auto-push: true
          comment-on-alert: true
          fail-on-alert: false
          max-items-in-chart: 60
          ref: ${{ github.sha }}
         